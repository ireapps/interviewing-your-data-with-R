---
title: "Finding the story in salaries data"
output: 
html_notebook: default
---

Now you'll put into practice the functions you've learned so far to interrogate some salary data from Bloomington, IN that came from a records request. We have cleaned up the data a little for the purposes of this class, but left it in spreadsheet format, so shortly you'll learn how to import data from an Excel file (either .xls or .xlsx).

First, open up Bloomington_Salaries.xlsx in Excel by double-clicking on the file in Finder. Note that it has two tabs: one with the data, an
another with notes on the Source. This is best practice for keeping track of when and where you received data. But you only want to import the first tab into R for analysis. 

To do that, we need a new R package called `readxl`. This was installed in Introduction.Rmd, but in order to use the functions that are included in the package, you'll need to *import* it into this script using the library() function, along with `tidyverse`:
```{r}
library(tidyverse)
library(readxl)
library(data.table)
```

There are many functions available in `readxl`, the one you'll use now is read_excel(). This function has an optional argument called "sheet" which allows you to specify, numerically, which sheet or sheets you want to import. We want the first one:
```{r}
read_excel("data/Bloomington Salaries.xlsx", sheet=1)
```

Remember! The results of any function - including read_excel() - either print to the console or save to a variable. If you want to refer to this data table later and pipe it into functions, you need to save it to a variable. Call it "salaries":
```{r}
salaries <- read_excel("data/Bloomington Salaries.xlsx", sheet=1)
```

Take a look at the salaries data: click on the word "salaries" in your Environment (upper right). 
Take a minute or two to look at the data:
What is one row of data? (One employee)
What columns of information do you have?
Note that there are NAs in the overtime, hourly_rate, and salary_2021 columns. NAs are *NULL* values, not blanks.

# Practice #

Start with some basic questions: 
*Your turn!*  How many employees in our data? (You may already know the answer to this, but write some code anyway!)
```{r}

```

*Your turn!*  Who made the most in total compensation? Who made the least? (Hint: use arrange() to sort your data)
```{r}

```

*Your turn!*  Who made the most in overtime/oncall pay? 
```{r}

```

What do you see in the results? What questions does that spark for you, a journalist? What questions might you have for the city? 

What is the total payroll for the city? 
Reminder: when you're no longer asking questions with regard to specific employees, your unit of analysis has changed. If you want to look at payroll for the whole city, you need to do some aggregating. In this case, we want to sum up payroll for the entire dataset: 
```{r}
salaries %>% summarise(total_payroll = sum(total_comp))
```

What is the total overtime/oncall pay? 
```{r}
salaries %>% summarise(total_payroll = sum(overtime_oncall))
```

Here's where NAs (NULLs) will trip you up. If you sum a column with NAs in it, R will return an NA. So you need to exclude the NAs in your summing. Thankfully there is an EASY way to do this; the sum() function will take an additional argument: `na.rm=T`, which means remove NAs. Adding it looks like this: 
```{r}
salaries %>% summarise(total_payroll = sum(overtime_oncall, na.rm=T))
```

That's why it's important to take note of NAs in your data!
Anytime you want to sum a column with NAs, you needt to include this argument in the sum function: `na.rm=T`

*Your turn!* What's the average and median hourly rate? Salary? (Note: both of these have NAs, so code accordingly)
```{r}

```

# Getting to know your data #

There's a very useful function in tidyverse for assessing what's in a particular column. For example, if you are familiar with SQL, this is the equivalent of the "golden query." If you regularly use spreadsheets, this is the equivalent of putting a column in the Rows box and calculating the count() function on each group. 

This function happens to be called count(). Try it out on the job_title column: 
```{r}
salaries %>% count(job_title)
```

You see a list of all unique job titles and how many times each value appears in the data (i.e. how many rows have that value in the job_title column). The count() function automatically labels the values column `n`.
Re-sort the results to see which job titles are the most common: 
```{r}
salaries %>% count(job_title) %>% arrange(desc(n))
```

*Your turn!* Try using the count() function on department. How clean are the department names?
```{r}

```

 
# Asking questions #

How many people work for the police department? 
```{r}
salaries %>% filter(department == "Police")
```

What's the average compensation for a police employee?
```{r}
salaries %>% filter(department == "Police") %>% summarise(avg_pay = mean(total_comp))
```

*Your turn!* Calculate the average compensation for each job title within the Police department:
```{r}

```

How does the average police compensation compare to other departments? Calculate the average compensation by department, using group_by():
```{r}
salaries %>% 
  group_by(department) %>% 
  summarise(avg_comp = mean(total_comp)) %>% 
  arrange(desc(avg_comp))
```

